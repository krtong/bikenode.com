{
    "sourceFile": "combine_motorcycles.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 3,
            "patches": [
                {
                    "date": 1740795271845,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1740797479935,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,9 +1,9 @@\n import os\n import pandas as pd\n import glob\n \n-def combine_motorcycle_data(data_dir='./data', output_file='motorcycle_database.xlsx'):\n+def combine_motorcycle_data(data_dir='./data', output_file='motorcycle_database.csv'):\n     \"\"\"\n     Combine all motorcycle data files into a single Excel spreadsheet with columns:\n     year | make | model | category | engine\n     \"\"\"\n"
                },
                {
                    "date": 1740797542924,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -3,9 +3,9 @@\n import glob\n \n def combine_motorcycle_data(data_dir='./data', output_file='motorcycle_database.csv'):\n     \"\"\"\n-    Combine all motorcycle data files into a single Excel spreadsheet with columns:\n+    Combine all motorcycle data files into a single CSV file with columns:\n     year | make | model | category | engine\n     \"\"\"\n     # Get all files matching the pattern YYYY_motorcycles\n     files = glob.glob(os.path.join(data_dir, '*_motorcycles'))\n@@ -58,10 +58,10 @@\n     combined_df = pd.concat(all_dfs, ignore_index=True)\n     \n     print(f\"Combined data: {len(combined_df)} total motorcycle models\")\n     \n-    # Save to Excel\n-    combined_df.to_excel(output_file, index=False)\n+    # Save to CSV instead of Excel\n+    combined_df.to_csv(output_file, index=False)\n     print(f\"Data saved to {output_file}\")\n \n if __name__ == \"__main__\":\n     combine_motorcycle_data()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1740797572642,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,67 @@\n+import os\n+import pandas as pd\n+import glob\n+\n+def combine_motorcycle_data(data_dir='./data', output_file='motorcycle_database.csv'):\n+    \"\"\"\n+    Combine all motorcycle data files into a single CSV file with columns:\n+    year | make | model | category | engine\n+    \"\"\"\n+    # Get all files matching the pattern YYYY_motorcycles\n+    files = glob.glob(os.path.join(data_dir, '*_motorcycles'))\n+    \n+    # Sort files by year\n+    files.sort()\n+    \n+    # Create an empty list to hold all dataframes\n+    all_dfs = []\n+    \n+    print(f\"Found {len(files)} files to process...\")\n+    \n+    # Process each file\n+    for file_path in files:\n+        # Extract year from filename\n+        year = os.path.basename(file_path).split('_')[0]\n+        \n+        try:\n+            # Read the file as TSV\n+            df = pd.read_csv(file_path, sep='\\t')\n+            \n+            # Fix column names (first column has year in it)\n+            column_names = df.columns.tolist()\n+            column_names[0] = \"Full_Model_Name\"  # Temporary name\n+            df.columns = column_names\n+            \n+            # Split make and model\n+            df['Make'] = df['Full_Model_Name'].apply(lambda x: x.split(' ')[0])\n+            df['Model'] = df['Full_Model_Name'].apply(lambda x: ' '.join(x.split(' ')[1:]))\n+            \n+            # Add year column\n+            df['Year'] = year\n+            \n+            # Select and reorder columns\n+            df = df[['Year', 'Make', 'Model', 'Category', 'Engine']]\n+            \n+            # Append to our list\n+            all_dfs.append(df)\n+            \n+            print(f\"Processed data for year {year} - found {len(df)} models\")\n+            \n+        except Exception as e:\n+            print(f\"Error processing {file_path}: {e}\")\n+    \n+    if not all_dfs:\n+        print(\"No data was loaded. Check file paths and formats.\")\n+        return\n+    \n+    # Combine all dataframes\n+    combined_df = pd.concat(all_dfs, ignore_index=True)\n+    \n+    print(f\"Combined data: {len(combined_df)} total motorcycle models\")\n+    \n+    # Save to CSV instead of Excel\n+    combined_df.to_csv(output_file, index=False)\n+    print(f\"Data saved to {output_file}\")\n+\n+if __name__ == \"__main__\":\n+    combine_motorcycle_data()\n\\ No newline at end of file\n"
                }
            ],
            "date": 1740795271845,
            "name": "Commit-0",
            "content": "import os\nimport pandas as pd\nimport glob\n\ndef combine_motorcycle_data(data_dir='./data', output_file='motorcycle_database.xlsx'):\n    \"\"\"\n    Combine all motorcycle data files into a single Excel spreadsheet with columns:\n    year | make | model | category | engine\n    \"\"\"\n    # Get all files matching the pattern YYYY_motorcycles\n    files = glob.glob(os.path.join(data_dir, '*_motorcycles'))\n    \n    # Sort files by year\n    files.sort()\n    \n    # Create an empty list to hold all dataframes\n    all_dfs = []\n    \n    print(f\"Found {len(files)} files to process...\")\n    \n    # Process each file\n    for file_path in files:\n        # Extract year from filename\n        year = os.path.basename(file_path).split('_')[0]\n        \n        try:\n            # Read the file as TSV\n            df = pd.read_csv(file_path, sep='\\t')\n            \n            # Fix column names (first column has year in it)\n            column_names = df.columns.tolist()\n            column_names[0] = \"Full_Model_Name\"  # Temporary name\n            df.columns = column_names\n            \n            # Split make and model\n            df['Make'] = df['Full_Model_Name'].apply(lambda x: x.split(' ')[0])\n            df['Model'] = df['Full_Model_Name'].apply(lambda x: ' '.join(x.split(' ')[1:]))\n            \n            # Add year column\n            df['Year'] = year\n            \n            # Select and reorder columns\n            df = df[['Year', 'Make', 'Model', 'Category', 'Engine']]\n            \n            # Append to our list\n            all_dfs.append(df)\n            \n            print(f\"Processed data for year {year} - found {len(df)} models\")\n            \n        except Exception as e:\n            print(f\"Error processing {file_path}: {e}\")\n    \n    if not all_dfs:\n        print(\"No data was loaded. Check file paths and formats.\")\n        return\n    \n    # Combine all dataframes\n    combined_df = pd.concat(all_dfs, ignore_index=True)\n    \n    print(f\"Combined data: {len(combined_df)} total motorcycle models\")\n    \n    # Save to Excel\n    combined_df.to_excel(output_file, index=False)\n    print(f\"Data saved to {output_file}\")\n\nif __name__ == \"__main__\":\n    combine_motorcycle_data()"
        }
    ]
}